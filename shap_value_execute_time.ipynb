{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e74bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(r'/Users/fuchuenli/Desktop/Data Science /Year 2/Trimester 2/COMP SCI 7097/GP-SHAP/Shapley Prior'))\n",
    "sys.path.append(os.path.abspath(r'/Users/fuchuenli/Desktop/Data Science /Year 2/Trimester 2/COMP SCI 7097/RKHS-SHAP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7778b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from sklearn.datasets import load_diabetes\n",
    "import matplotlib.pylab as plt\n",
    "from gpytorch.lazy import lazify\n",
    "\n",
    "from src.gp_model.VariationalGPRegression import VariationalGPRegression\n",
    "from src.explanation_algorithms.BayesGPSHAP import BayesGPSHAP\n",
    "from src.predictive_explanation.ShapleyPrior import ShapleyPrior\n",
    "from src.utils.visualisation import summary_plot\n",
    "from src.predictive_explanation.ShapleyKernel import ShapleyKernel\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from math import comb\n",
    "\n",
    "import fastshap\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4634d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pickle, warnings, torch, shap\n",
    "\n",
    "import numpy as np\n",
    "from experiments.BananaShapley.banana_distribution import Banana2d\n",
    "from experiments.BananaShapley.gshap_banana import Observation2dBanana\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import mean_squared_error, pairwise_distances, r2_score\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e59589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengthscale: tensor([3.0637, 0.9047])\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "v = 10\n",
    "b = 0.01\n",
    "iterations = 10\n",
    "result = []\n",
    "\n",
    "banana2d = Banana2d(n=n, v=v, b=b, noise=0, outlier_quantile=2.)\n",
    "\n",
    "# Scaled the output so that can we compare accuracy across\n",
    "scale = 1\n",
    "y = torch.Tensor(banana2d.y/scale)\n",
    "X = torch.Tensor(banana2d.X)\n",
    "d = X.shape[1]\n",
    "\n",
    "compute_mh = lambda X: np.array([np.median(pairwise_distances(X[:, [i]])) for i in range(X.shape[1])])\n",
    "lengthscale = torch.tensor(compute_mh(X)).float()\n",
    "lengthscale[1] *= 1\n",
    "print(\"Lengthscale:\", lengthscale)\n",
    "\n",
    "# True OSVs:\n",
    "phi1 = banana2d.phi_1/scale\n",
    "phi2 = banana2d.phi_2/scale\n",
    "PHI = np.array([phi1, phi2]).T\n",
    "\n",
    "# True ISVs:\n",
    "phi1_I = banana2d.phi_1_I\n",
    "phi2_I = banana2d.phi_2_I\n",
    "PHI_I = np.array([phi1_I, phi2_I]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed8b4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutting_points = 800\n",
    "\n",
    "X_train = X[:cutting_points]\n",
    "y_train = y[:cutting_points]\n",
    "X_test = X[cutting_points:]\n",
    "y_test = y[cutting_points:]\n",
    "\n",
    "PHI_train = PHI[:cutting_points]\n",
    "PHI_test = PHI[cutting_points:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "286aceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd10596fdbf47edab6cede2f40754a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kernel = RBFKernel\n",
    "gp_regression = VariationalGPRegression(\n",
    "    X_train, y_train, kernel=kernel, num_inducing_points=200, batch_size=128)\n",
    "\n",
    "gp_regression.fit(learning_rate=1e-2,\n",
    "                  training_iteration=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c428792",
   "metadata": {},
   "source": [
    "## Fast-SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ef6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap.utils import MaskLayer1d\n",
    "from fastshap import Surrogate, KLDivLoss\n",
    "from fastshap import FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c3768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastshap_training_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f7668a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch = 1 -----\n",
      "Val loss = 0.5941\n",
      "\n",
      "New best epoch, loss = 0.5941\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.4565\n",
      "\n",
      "New best epoch, loss = 0.4565\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.4540\n",
      "\n",
      "New best epoch, loss = 0.4540\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.4754\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.4537\n",
      "\n",
      "New best epoch, loss = 0.4537\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.4435\n",
      "\n",
      "New best epoch, loss = 0.4435\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.4542\n",
      "\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.4423\n",
      "\n",
      "New best epoch, loss = 0.4423\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.4407\n",
      "\n",
      "New best epoch, loss = 0.4407\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.4481\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.4390\n",
      "\n",
      "New best epoch, loss = 0.4390\n",
      "\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.4485\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.4382\n",
      "\n",
      "New best epoch, loss = 0.4382\n",
      "\n",
      "----- Epoch = 14 -----\n",
      "Val loss = 0.4368\n",
      "\n",
      "New best epoch, loss = 0.4368\n",
      "\n",
      "----- Epoch = 15 -----\n",
      "Val loss = 0.4348\n",
      "\n",
      "New best epoch, loss = 0.4348\n",
      "\n",
      "----- Epoch = 16 -----\n",
      "Val loss = 0.4340\n",
      "\n",
      "New best epoch, loss = 0.4340\n",
      "\n",
      "----- Epoch = 17 -----\n",
      "Val loss = 0.4598\n",
      "\n",
      "----- Epoch = 18 -----\n",
      "Val loss = 0.4528\n",
      "\n",
      "----- Epoch = 19 -----\n",
      "Val loss = 0.4513\n",
      "\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-04.\n",
      "----- Epoch = 20 -----\n",
      "Val loss = 0.4450\n",
      "\n",
      "----- Epoch = 21 -----\n",
      "Val loss = 0.4448\n",
      "\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "surr = nn.Sequential(\n",
    "    MaskLayer1d(value=0, append=True),\n",
    "    nn.Linear(2 * d, 128),\n",
    "    nn.ELU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ELU(inplace=True),\n",
    "    nn.Linear(128, 1)\n",
    ")\n",
    "\n",
    "surrogate = Surrogate(surr, d)\n",
    "\n",
    "def original_model(x):\n",
    "    return gp_regression.predict(x).mean.detach().reshape(-1, 1).float()\n",
    "\n",
    "surrogate.train_original_model(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    original_model,\n",
    "    batch_size=64,\n",
    "    max_epochs=100,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    validation_samples=10,\n",
    "    validation_batch_size=10000,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0069c74a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch = 1 -----\n",
      "Val loss = 0.434067\n",
      "\n",
      "New best epoch, loss = 0.434067\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.354913\n",
      "\n",
      "New best epoch, loss = 0.354913\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.280279\n",
      "\n",
      "New best epoch, loss = 0.280279\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.214861\n",
      "\n",
      "New best epoch, loss = 0.214861\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.154887\n",
      "\n",
      "New best epoch, loss = 0.154887\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.106269\n",
      "\n",
      "New best epoch, loss = 0.106269\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.070018\n",
      "\n",
      "New best epoch, loss = 0.070018\n",
      "\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.045128\n",
      "\n",
      "New best epoch, loss = 0.045128\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.031002\n",
      "\n",
      "New best epoch, loss = 0.031002\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.023360\n",
      "\n",
      "New best epoch, loss = 0.023360\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.019350\n",
      "\n",
      "New best epoch, loss = 0.019350\n",
      "\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.017053\n",
      "\n",
      "New best epoch, loss = 0.017053\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.015031\n",
      "\n",
      "New best epoch, loss = 0.015031\n",
      "\n",
      "----- Epoch = 14 -----\n",
      "Val loss = 0.013893\n",
      "\n",
      "New best epoch, loss = 0.013893\n",
      "\n",
      "----- Epoch = 15 -----\n",
      "Val loss = 0.012940\n",
      "\n",
      "New best epoch, loss = 0.012940\n",
      "\n",
      "----- Epoch = 16 -----\n",
      "Val loss = 0.012344\n",
      "\n",
      "New best epoch, loss = 0.012344\n",
      "\n",
      "----- Epoch = 17 -----\n",
      "Val loss = 0.011802\n",
      "\n",
      "New best epoch, loss = 0.011802\n",
      "\n",
      "----- Epoch = 18 -----\n",
      "Val loss = 0.011421\n",
      "\n",
      "New best epoch, loss = 0.011421\n",
      "\n",
      "----- Epoch = 19 -----\n",
      "Val loss = 0.011025\n",
      "\n",
      "New best epoch, loss = 0.011025\n",
      "\n",
      "----- Epoch = 20 -----\n",
      "Val loss = 0.010791\n",
      "\n",
      "New best epoch, loss = 0.010791\n",
      "\n",
      "----- Epoch = 21 -----\n",
      "Val loss = 0.010569\n",
      "\n",
      "New best epoch, loss = 0.010569\n",
      "\n",
      "----- Epoch = 22 -----\n",
      "Val loss = 0.010400\n",
      "\n",
      "New best epoch, loss = 0.010400\n",
      "\n",
      "----- Epoch = 23 -----\n",
      "Val loss = 0.010270\n",
      "\n",
      "New best epoch, loss = 0.010270\n",
      "\n",
      "----- Epoch = 24 -----\n",
      "Val loss = 0.010154\n",
      "\n",
      "New best epoch, loss = 0.010154\n",
      "\n",
      "----- Epoch = 25 -----\n",
      "Val loss = 0.010074\n",
      "\n",
      "New best epoch, loss = 0.010074\n",
      "\n",
      "----- Epoch = 26 -----\n",
      "Val loss = 0.009972\n",
      "\n",
      "New best epoch, loss = 0.009972\n",
      "\n",
      "----- Epoch = 27 -----\n",
      "Val loss = 0.009959\n",
      "\n",
      "New best epoch, loss = 0.009959\n",
      "\n",
      "----- Epoch = 28 -----\n",
      "Val loss = 0.009869\n",
      "\n",
      "New best epoch, loss = 0.009869\n",
      "\n",
      "----- Epoch = 29 -----\n",
      "Val loss = 0.009843\n",
      "\n",
      "New best epoch, loss = 0.009843\n",
      "\n",
      "----- Epoch = 30 -----\n",
      "Val loss = 0.009779\n",
      "\n",
      "New best epoch, loss = 0.009779\n",
      "\n",
      "----- Epoch = 31 -----\n",
      "Val loss = 0.009769\n",
      "\n",
      "New best epoch, loss = 0.009769\n",
      "\n",
      "----- Epoch = 32 -----\n",
      "Val loss = 0.009723\n",
      "\n",
      "New best epoch, loss = 0.009723\n",
      "\n",
      "----- Epoch = 33 -----\n",
      "Val loss = 0.009739\n",
      "\n",
      "----- Epoch = 34 -----\n",
      "Val loss = 0.009698\n",
      "\n",
      "New best epoch, loss = 0.009698\n",
      "\n",
      "----- Epoch = 35 -----\n",
      "Val loss = 0.009679\n",
      "\n",
      "New best epoch, loss = 0.009679\n",
      "\n",
      "----- Epoch = 36 -----\n",
      "Val loss = 0.009652\n",
      "\n",
      "New best epoch, loss = 0.009652\n",
      "\n",
      "----- Epoch = 37 -----\n",
      "Val loss = 0.009621\n",
      "\n",
      "New best epoch, loss = 0.009621\n",
      "\n",
      "----- Epoch = 38 -----\n",
      "Val loss = 0.009616\n",
      "\n",
      "New best epoch, loss = 0.009616\n",
      "\n",
      "----- Epoch = 39 -----\n",
      "Val loss = 0.009600\n",
      "\n",
      "New best epoch, loss = 0.009600\n",
      "\n",
      "----- Epoch = 40 -----\n",
      "Val loss = 0.009626\n",
      "\n",
      "----- Epoch = 41 -----\n",
      "Val loss = 0.009583\n",
      "\n",
      "New best epoch, loss = 0.009583\n",
      "\n",
      "----- Epoch = 42 -----\n",
      "Val loss = 0.009592\n",
      "\n",
      "----- Epoch = 43 -----\n",
      "Val loss = 0.009588\n",
      "\n",
      "----- Epoch = 44 -----\n",
      "Val loss = 0.009549\n",
      "\n",
      "New best epoch, loss = 0.009549\n",
      "\n",
      "----- Epoch = 45 -----\n",
      "Val loss = 0.009531\n",
      "\n",
      "New best epoch, loss = 0.009531\n",
      "\n",
      "----- Epoch = 46 -----\n",
      "Val loss = 0.009550\n",
      "\n",
      "----- Epoch = 47 -----\n",
      "Val loss = 0.009515\n",
      "\n",
      "New best epoch, loss = 0.009515\n",
      "\n",
      "----- Epoch = 48 -----\n",
      "Val loss = 0.009545\n",
      "\n",
      "----- Epoch = 49 -----\n",
      "Val loss = 0.009513\n",
      "\n",
      "New best epoch, loss = 0.009513\n",
      "\n",
      "----- Epoch = 50 -----\n",
      "Val loss = 0.009511\n",
      "\n",
      "New best epoch, loss = 0.009511\n",
      "\n",
      "----- Epoch = 51 -----\n",
      "Val loss = 0.009496\n",
      "\n",
      "New best epoch, loss = 0.009496\n",
      "\n",
      "----- Epoch = 52 -----\n",
      "Val loss = 0.009507\n",
      "\n",
      "----- Epoch = 53 -----\n",
      "Val loss = 0.009490\n",
      "\n",
      "New best epoch, loss = 0.009490\n",
      "\n",
      "----- Epoch = 54 -----\n",
      "Val loss = 0.009487\n",
      "\n",
      "New best epoch, loss = 0.009487\n",
      "\n",
      "----- Epoch = 55 -----\n",
      "Val loss = 0.009552\n",
      "\n",
      "----- Epoch = 56 -----\n",
      "Val loss = 0.009489\n",
      "\n",
      "----- Epoch = 57 -----\n",
      "Val loss = 0.009537\n",
      "\n",
      "Epoch 00057: reducing learning rate of group 0 to 1.0000e-04.\n",
      "----- Epoch = 58 -----\n",
      "Val loss = 0.009465\n",
      "\n",
      "New best epoch, loss = 0.009465\n",
      "\n",
      "----- Epoch = 59 -----\n",
      "Val loss = 0.009478\n",
      "\n",
      "----- Epoch = 60 -----\n",
      "Val loss = 0.009466\n",
      "\n",
      "----- Epoch = 61 -----\n",
      "Val loss = 0.009462\n",
      "\n",
      "New best epoch, loss = 0.009462\n",
      "\n",
      "----- Epoch = 62 -----\n",
      "Val loss = 0.009464\n",
      "\n",
      "----- Epoch = 63 -----\n",
      "Val loss = 0.009460\n",
      "\n",
      "New best epoch, loss = 0.009460\n",
      "\n",
      "----- Epoch = 64 -----\n",
      "Val loss = 0.009464\n",
      "\n",
      "----- Epoch = 65 -----\n",
      "Val loss = 0.009457\n",
      "\n",
      "New best epoch, loss = 0.009457\n",
      "\n",
      "----- Epoch = 66 -----\n",
      "Val loss = 0.009458\n",
      "\n",
      "----- Epoch = 67 -----\n",
      "Val loss = 0.009458\n",
      "\n",
      "----- Epoch = 68 -----\n",
      "Val loss = 0.009449\n",
      "\n",
      "New best epoch, loss = 0.009449\n",
      "\n",
      "----- Epoch = 69 -----\n",
      "Val loss = 0.009468\n",
      "\n",
      "----- Epoch = 70 -----\n",
      "Val loss = 0.009447\n",
      "\n",
      "New best epoch, loss = 0.009447\n",
      "\n",
      "----- Epoch = 71 -----\n",
      "Val loss = 0.009461\n",
      "\n",
      "----- Epoch = 72 -----\n",
      "Val loss = 0.009449\n",
      "\n",
      "----- Epoch = 73 -----\n",
      "Val loss = 0.009446\n",
      "\n",
      "New best epoch, loss = 0.009446\n",
      "\n",
      "----- Epoch = 74 -----\n",
      "Val loss = 0.009451\n",
      "\n",
      "----- Epoch = 75 -----\n",
      "Val loss = 0.009440\n",
      "\n",
      "New best epoch, loss = 0.009440\n",
      "\n",
      "----- Epoch = 76 -----\n",
      "Val loss = 0.009467\n",
      "\n",
      "----- Epoch = 77 -----\n",
      "Val loss = 0.009434\n",
      "\n",
      "New best epoch, loss = 0.009434\n",
      "\n",
      "----- Epoch = 78 -----\n",
      "Val loss = 0.009446\n",
      "\n",
      "----- Epoch = 79 -----\n",
      "Val loss = 0.009433\n",
      "\n",
      "New best epoch, loss = 0.009433\n",
      "\n",
      "----- Epoch = 80 -----\n",
      "Val loss = 0.009446\n",
      "\n",
      "Epoch 00080: reducing learning rate of group 0 to 5.0000e-05.\n",
      "----- Epoch = 81 -----\n",
      "Val loss = 0.009433\n",
      "\n",
      "New best epoch, loss = 0.009433\n",
      "\n",
      "----- Epoch = 82 -----\n",
      "Val loss = 0.009436\n",
      "\n",
      "----- Epoch = 83 -----\n",
      "Val loss = 0.009434\n",
      "\n",
      "----- Epoch = 84 -----\n",
      "Val loss = 0.009449\n",
      "\n",
      "Epoch 00084: reducing learning rate of group 0 to 2.5000e-05.\n",
      "----- Epoch = 85 -----\n",
      "Val loss = 0.009439\n",
      "\n",
      "----- Epoch = 86 -----\n",
      "Val loss = 0.009430\n",
      "\n",
      "New best epoch, loss = 0.009430\n",
      "\n",
      "----- Epoch = 87 -----\n",
      "Val loss = 0.009433\n",
      "\n",
      "----- Epoch = 88 -----\n",
      "Val loss = 0.009441\n",
      "\n",
      "----- Epoch = 89 -----\n",
      "Val loss = 0.009434\n",
      "\n",
      "Epoch 00089: reducing learning rate of group 0 to 1.2500e-05.\n",
      "----- Epoch = 90 -----\n",
      "Val loss = 0.009433\n",
      "\n",
      "----- Epoch = 91 -----\n",
      "Val loss = 0.009431\n",
      "\n",
      "Stopping early at epoch = 90\n"
     ]
    }
   ],
   "source": [
    "explainer = nn.Sequential(\n",
    "    nn.Linear(d, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * d))\n",
    "\n",
    "# Set up FastSHAP object\n",
    "fastshap = FastSHAP(explainer, surrogate, normalization='additive')\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    validation_samples=128,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3218238",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastshap_training_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50bab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastshap_training_time = fastshap_training_end - fastshap_training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a61eb626",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastshap_implementation_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a01b1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastshap predictions\n",
    "fastshap_preds = [fastshap.shap_values(X_test[i:i+1])[0].mean(axis=1) for i in range(X.shape[0] - 300)]\n",
    "fastshap_preds = torch.tensor(fastshap_preds).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5d7fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastshap_implementation_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2acad16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_shap_implementation_time = fastshap_implementation_end - fastshap_implementation_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f590f1",
   "metadata": {},
   "source": [
    "## Shapley Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d4155b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesgpshap = BayesGPSHAP(train_X=X, kernel=RBFKernel(), gp_model=gp_regression,\n",
    "                          include_likelihood_noise_for_explanation=False, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f7489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 438.46it/s]\n"
     ]
    }
   ],
   "source": [
    "bayesgpshap.run_bayesSHAP(X=X, num_coalitions=2**d)\n",
    "explanations = bayesgpshap.mean_shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3347438",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_prior_training_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b81300c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4467, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4463, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4458, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4454, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4449, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4444, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4440, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4435, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4430, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4425, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4421, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4416, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4411, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4406, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4400, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4395, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4390, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4385, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4379, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4374, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4368, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4363, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4357, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4351, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4345, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4339, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4333, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4327, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4321, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4314, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4308, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4301, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4295, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4288, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4281, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4274, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4267, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4260, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4252, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4245, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4237, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4230, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4222, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4214, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4206, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4198, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4190, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4181, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4173, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4164, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4155, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4147, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4138, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4129, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4120, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4110, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4101, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4091, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4082, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4072, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4062, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4052, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4042, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4032, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4021, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4011, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4000, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3989, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3978, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3967, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3956, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3944, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3933, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3922, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3910, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3898, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3886, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3873, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3861, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3848, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3835, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3823, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3810, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3796, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3783, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3770, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3756, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3742, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3728, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3700, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3686, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3671, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3657, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3642, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3628, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3613, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3598, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3583, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3568, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3552, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3537, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3522, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3506, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3491, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3476, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3460, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3445, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3430, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3414, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3399, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3384, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3368, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3353, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3338, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3323, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3308, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3293, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3278, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3263, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3249, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3234, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3219, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3205, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3191, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3178, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3163, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3150, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3137, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3123, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3109, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3096, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3083, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3070, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3058, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3045, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3032, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3020, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3008, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2995, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2984, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2971, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2959, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2948, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2937, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2925, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2914, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2903, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2892, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2880, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target = explanations.t().reshape(-1, 1)\n",
    "shapley_kernel = ShapleyKernel(\n",
    "    train_X=X, kernel=RBFKernel(), lengthscales=gp_regression.lengthscale, \n",
    "    inducing_points=gp_regression.inducing_points,\n",
    "    num_coalitions=2**(d-1), sampling_method=\"subsampling\", verbose=False\n",
    ")\n",
    "\n",
    "target_train = target[:cutting_points*d]\n",
    "\n",
    "optim = torch.optim.Adam(shapley_kernel.parameters(), lr=1e-3)\n",
    "def loss_function(pred, true):\n",
    "    return torch.mean((true - pred) **2)\n",
    "\n",
    "for _ in range(150):\n",
    "    optim.zero_grad()\n",
    "    Psi = shapley_kernel(X)\n",
    "    K = torch.einsum(\"ijk,lmn->imkn\", Psi, Psi.transpose(0, 1))\n",
    "    K = K.permute(2, 0, 3, 1).resize(len(target), len(target))\n",
    "    K_train = K[:cutting_points*d, :cutting_points*d]\n",
    "    prediction = K_train @ lazify(K_train).add_diag(shapley_kernel.krr_regularisation).inv_matmul(target_train)\n",
    "    loss = loss_function(prediction, target_train)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a79f7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_prior_training_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d74e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_prior_training_time = shapley_prior_training_end - shapley_prior_training_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaf2f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_prior_implementation_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7521a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = shapley_kernel(X)\n",
    "K = torch.einsum(\"ijk,lmn->imkn\", Psi, Psi.transpose(0, 1))\n",
    "K = K.permute(2, 0, 3, 1).resize(len(target), len(target))\n",
    "\n",
    "K_train = K[:cutting_points*d, :cutting_points*d]\n",
    "K_test_train = K[cutting_points*d:, :cutting_points*d]\n",
    "\n",
    "train_target = target[:cutting_points*d]\n",
    "test_target = target[cutting_points*d:]\n",
    "\n",
    "pred = K_test_train @ lazify(K_train).add_diag(shapley_kernel.krr_regularisation).inv_matmul(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a840db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.reshape((-1, 2)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0a49215",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_prior_implementation_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dfa048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_prior_implementation_time = shapley_prior_implementation_end - shapley_prior_implementation_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51218da5",
   "metadata": {},
   "source": [
    "## KernelSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb482428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Assume this is your custom model class\n",
    "class CustomModel:\n",
    "    def predict_custom(self, data):\n",
    "        # Your prediction logic here\n",
    "        pred = []\n",
    "        for i in range(data.shape[0]):\n",
    "            pred.append(gp_regression.predict(torch.Tensor(data[i]).reshape((1,d))).loc.item())\n",
    "        return np.array(pred)\n",
    "\n",
    "# Create an instance of your model\n",
    "model = CustomModel()\n",
    "\n",
    "# Define a wrapper function for the model's prediction\n",
    "def model_predict(data):\n",
    "    return model.predict_custom(data)\n",
    "\n",
    "# # Say you have some training data X_train and you want to explain predictions on X_test\n",
    "# background_data = X_train\n",
    "# explainer = shap.KernelExplainer(model_predict, X.numpy())\n",
    "\n",
    "# # Compute SHAP values for a specific instance (or multiple instances)\n",
    "# shap_values = explainer.shap_values(X_test.numpy())\n",
    "\n",
    "# # Now you can visualize or analyze the SHAP values as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fc8b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "gshap_implementation_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af36788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [00:32<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "ogshap = Observation2dBanana(model_predict, X_test.numpy())\n",
    "ophi1, ophi2 = ogshap.fit(X_test, num_samples=X_test.shape[0])    \n",
    "OPHI = np.array([ophi1,ophi2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d15f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "gshap_implementation_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "728b1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gshap_implementation_time = gshap_implementation_end_time - gshap_implementation_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52aee31",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d7a89d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHAP</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Implementation Time</th>\n",
       "      <th>Total Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSHAP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.349118</td>\n",
       "      <td>34.349118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FastSHAP</td>\n",
       "      <td>9.027937</td>\n",
       "      <td>0.128644</td>\n",
       "      <td>9.156581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ShapleyPrior</td>\n",
       "      <td>7.636084</td>\n",
       "      <td>0.111606</td>\n",
       "      <td>7.747690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SHAP  Training Time  Implementation Time  Total Time\n",
       "0         GSHAP       0.000000            34.349118   34.349118\n",
       "1      FastSHAP       9.027937             0.128644    9.156581\n",
       "2  ShapleyPrior       7.636084             0.111606    7.747690"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"SHAP\": [\"GSHAP\", \"FastSHAP\", \"ShapleyPrior\"], \"Training Time\":[0, fastshap_training_time, shapley_prior_training_time], \"Implementation Time\": [gshap_implementation_time, fast_shap_implementation_time, shapley_prior_implementation_time]})\n",
    "results[\"Total Time\"] = results[\"Training Time\"] + results[\"Implementation Time\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b28ffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Time(s)')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=results, x=\"SHAP\", y=\"Total Time\")\n",
    "plt.title(\"SHAP Execution Time\")\n",
    "plt.xlabel(\"SHAP\")\n",
    "plt.ylabel(\"Time(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ad7a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengthscale: tensor([2.9562, 0.9340])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72cc90f4b104e07b431ec155b098a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch = 1 -----\n",
      "Val loss = 0.6454\n",
      "\n",
      "New best epoch, loss = 0.6454\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.5856\n",
      "\n",
      "New best epoch, loss = 0.5856\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.5990\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.5749\n",
      "\n",
      "New best epoch, loss = 0.5749\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.5934\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.5852\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.6161\n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-04.\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.5617\n",
      "\n",
      "New best epoch, loss = 0.5617\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.5792\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.5792\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.5672\n",
      "\n",
      "Epoch 00011: reducing learning rate of group 0 to 2.5000e-04.\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.5693\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.5858\n",
      "\n",
      "Stopping early\n",
      "----- Epoch = 1 -----\n",
      "Val loss = 0.388436\n",
      "\n",
      "New best epoch, loss = 0.388436\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.109054\n",
      "\n",
      "New best epoch, loss = 0.109054\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.025254\n",
      "\n",
      "New best epoch, loss = 0.025254\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.017699\n",
      "\n",
      "New best epoch, loss = 0.017699\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.014580\n",
      "\n",
      "New best epoch, loss = 0.014580\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.013080\n",
      "\n",
      "New best epoch, loss = 0.013080\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.012509\n",
      "\n",
      "New best epoch, loss = 0.012509\n",
      "\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.012350\n",
      "\n",
      "New best epoch, loss = 0.012350\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.011890\n",
      "\n",
      "New best epoch, loss = 0.011890\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.012163\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.012296\n",
      "\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.011779\n",
      "\n",
      "New best epoch, loss = 0.011779\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.011717\n",
      "\n",
      "New best epoch, loss = 0.011717\n",
      "\n",
      "----- Epoch = 14 -----\n",
      "Val loss = 0.011701\n",
      "\n",
      "New best epoch, loss = 0.011701\n",
      "\n",
      "----- Epoch = 15 -----\n",
      "Val loss = 0.011730\n",
      "\n",
      "----- Epoch = 16 -----\n",
      "Val loss = 0.011652\n",
      "\n",
      "New best epoch, loss = 0.011652\n",
      "\n",
      "----- Epoch = 17 -----\n",
      "Val loss = 0.011404\n",
      "\n",
      "New best epoch, loss = 0.011404\n",
      "\n",
      "----- Epoch = 18 -----\n",
      "Val loss = 0.011796\n",
      "\n",
      "----- Epoch = 19 -----\n",
      "Val loss = 0.011434\n",
      "\n",
      "----- Epoch = 20 -----\n",
      "Val loss = 0.011368\n",
      "\n",
      "New best epoch, loss = 0.011368\n",
      "\n",
      "----- Epoch = 21 -----\n",
      "Val loss = 0.011473\n",
      "\n",
      "----- Epoch = 22 -----\n",
      "Val loss = 0.011536\n",
      "\n",
      "----- Epoch = 23 -----\n",
      "Val loss = 0.011310\n",
      "\n",
      "New best epoch, loss = 0.011310\n",
      "\n",
      "----- Epoch = 24 -----\n",
      "Val loss = 0.011412\n",
      "\n",
      "----- Epoch = 25 -----\n",
      "Val loss = 0.011306\n",
      "\n",
      "New best epoch, loss = 0.011306\n",
      "\n",
      "----- Epoch = 26 -----\n",
      "Val loss = 0.011241\n",
      "\n",
      "New best epoch, loss = 0.011241\n",
      "\n",
      "----- Epoch = 27 -----\n",
      "Val loss = 0.011250\n",
      "\n",
      "----- Epoch = 28 -----\n",
      "Val loss = 0.011234\n",
      "\n",
      "New best epoch, loss = 0.011234\n",
      "\n",
      "----- Epoch = 29 -----\n",
      "Val loss = 0.011332\n",
      "\n",
      "----- Epoch = 30 -----\n",
      "Val loss = 0.011205\n",
      "\n",
      "New best epoch, loss = 0.011205\n",
      "\n",
      "----- Epoch = 31 -----\n",
      "Val loss = 0.011363\n",
      "\n",
      "----- Epoch = 32 -----\n",
      "Val loss = 0.011181\n",
      "\n",
      "New best epoch, loss = 0.011181\n",
      "\n",
      "----- Epoch = 33 -----\n",
      "Val loss = 0.011212\n",
      "\n",
      "----- Epoch = 34 -----\n",
      "Val loss = 0.011198\n",
      "\n",
      "----- Epoch = 35 -----\n",
      "Val loss = 0.011299\n",
      "\n",
      "Epoch 00035: reducing learning rate of group 0 to 1.0000e-04.\n",
      "----- Epoch = 36 -----\n",
      "Val loss = 0.011134\n",
      "\n",
      "New best epoch, loss = 0.011134\n",
      "\n",
      "----- Epoch = 37 -----\n",
      "Val loss = 0.011149\n",
      "\n",
      "----- Epoch = 38 -----\n",
      "Val loss = 0.011191\n",
      "\n",
      "----- Epoch = 39 -----\n",
      "Val loss = 0.011216\n",
      "\n",
      "Epoch 00039: reducing learning rate of group 0 to 5.0000e-05.\n",
      "----- Epoch = 40 -----\n",
      "Val loss = 0.011150\n",
      "\n",
      "----- Epoch = 41 -----\n",
      "Val loss = 0.011111\n",
      "\n",
      "New best epoch, loss = 0.011111\n",
      "\n",
      "----- Epoch = 42 -----\n",
      "Val loss = 0.011108\n",
      "\n",
      "New best epoch, loss = 0.011108\n",
      "\n",
      "----- Epoch = 43 -----\n",
      "Val loss = 0.011115\n",
      "\n",
      "----- Epoch = 44 -----\n",
      "Val loss = 0.011118\n",
      "\n",
      "----- Epoch = 45 -----\n",
      "Val loss = 0.011123\n",
      "\n",
      "Epoch 00045: reducing learning rate of group 0 to 2.5000e-05.\n",
      "----- Epoch = 46 -----\n",
      "Val loss = 0.011135\n",
      "\n",
      "----- Epoch = 47 -----\n",
      "Val loss = 0.011131\n",
      "\n",
      "Stopping early at epoch = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1715.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4482, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4478, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4476, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4474, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4472, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4468, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4465, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4461, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4459, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4456, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4453, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4453, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4447, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4443, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4442, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4438, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4435, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4433, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4430, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4427, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4426, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4421, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4421, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4417, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4415, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4413, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4409, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4406, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4404, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4401, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4397, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4396, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4396, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4392, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4388, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4386, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4383, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4381, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4378, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4376, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4373, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4372, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4368, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4366, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4362, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4361, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4357, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4356, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4352, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4350, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4347, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4345, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4341, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4338, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4337, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4335, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4332, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4329, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4325, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4323, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4322, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4317, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4315, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4313, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4310, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4308, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4302, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4302, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4299, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4294, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4293, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4290, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4286, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4284, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4281, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4279, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4274, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4271, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4270, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4266, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4262, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4260, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4257, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4253, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4249, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4245, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4245, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4240, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4236, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4235, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4230, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4227, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4223, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4220, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4216, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4214, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4209, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4206, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4202, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4197, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4195, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4192, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4188, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4183, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4179, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4177, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4172, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4169, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4165, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4160, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4157, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4152, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4149, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4144, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4140, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4137, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4133, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4128, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4123, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4120, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4114, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4110, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4107, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4102, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4097, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4092, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4088, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4082, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4079, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4075, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4070, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4065, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4061, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4054, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4050, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4046, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4040, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4037, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4034, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4026, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4021, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4016, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4011, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4006, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4001, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3997, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3991, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3987, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3981, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3975, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3972, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3965, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3962, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3956, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3951, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3945, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3939, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3936, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3928, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3926, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3920, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3914, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3912, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3907, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3901, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3891, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3885, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3882, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3876, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3871, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3867, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3861, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3854, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3852, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3847, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3841, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3837, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3829, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3825, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3820, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3815, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3810, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3803, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3800, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3793, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3788, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3782, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3776, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3771, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3768, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3761, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3747, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3743, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3709, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3700, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3694, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3685, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3678, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3670, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3663, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3653, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3633, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3623, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3612, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3603, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3589, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3579, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3566, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3552, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3541, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3529, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3517, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3508, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3500, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3491, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3486, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3481, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3478, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3471, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3464, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3456, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3448, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3442, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3437, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3433, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3428, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3424, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3421, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3417, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3410, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3406, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3401, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3395, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3388, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3384, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3378, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3373, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3370, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3365, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3360, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3355, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3350, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3345, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3340, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3335, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3330, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3326, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3321, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3316, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3312, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3308, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3302, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3298, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3292, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3288, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3283, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3279, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3274, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3270, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3264, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3261, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3256, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3250, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3247, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3242, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3238, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3232, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3227, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3224, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3219, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3213, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3209, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3204, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3200, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3195, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3191, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3187, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3181, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3176, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3172, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3168, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3163, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3159, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3155, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3151, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3146, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3142, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3138, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3134, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3130, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3126, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3121, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3117, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3113, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3111, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3105, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3103, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3098, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3095, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3091, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3088, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3084, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3079, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3075, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3072, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3068, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3063, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3060, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3058, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3052, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3049, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3046, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3041, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3038, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3034, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3031, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3027, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3024, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3019, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3016, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3012, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3008, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3005, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3002, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2998, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2994, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2990, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2987, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2983, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2980, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2976, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2973, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2969, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2965, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2961, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2958, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2955, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2952, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2947, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2944, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2941, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2937, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2934, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2930, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2927, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2923, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2920, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2916, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2913, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2909, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2906, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2903, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2899, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2896, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2892, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2888, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2885, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2882, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2877, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2875, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2872, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2867, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2865, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2862, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2858, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2856, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2852, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2848, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2844, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2843, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2839, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2834, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2832, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2829, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2826, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2821, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2818, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2815, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2811, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2809, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2806, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2802, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2799, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2796, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2792, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2789, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2786, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2783, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2779, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2776, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2773, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2770, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2766, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2763, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2760, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2757, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2750, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2747, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2744, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2740, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2734, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2727, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2725, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2721, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2708, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2705, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2702, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2699, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2695, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2693, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2689, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2686, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2683, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2680, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2676, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2672, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2670, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2663, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2661, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2657, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2653, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2651, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2647, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2641, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2638, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2634, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2631, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2628, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2625, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2622, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2618, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2615, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2612, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2608, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2606, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2602, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2599, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2595, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2592, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2588, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2586, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2582, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2579, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2576, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2572, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2569, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2566, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2562, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2560, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2556, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2552, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2550, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2546, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2542, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2539, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2536, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2533, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2529, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2525, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2522, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2518, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2515, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2512, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2508, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2505, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2502, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2499, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2495, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2492, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2489, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2486, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2483, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2479, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2476, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2472, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2470, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2466, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2463, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2460, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2457, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2455, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2451, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2448, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2445, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2442, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2439, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2436, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2433, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2430, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2427, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2424, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2420, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2417, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2414, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2411, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2408, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2405, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2402, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2399, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2396, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2393, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2390, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2387, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2383, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2381, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2378, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2375, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2372, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2368, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2366, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2362, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2359, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2357, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2353, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2351, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2347, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2344, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2341, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2338, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2335, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2332, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2329, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2326, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2323, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2320, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2317, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2314, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2311, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2308, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2305, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2302, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2299, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2296, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2293, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2289, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2287, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2284, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2280, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2278, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2274, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2272, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2269, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2266, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2263, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2259, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2257, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2253, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2251, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2247, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2244, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2241, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2238, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2235, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2231, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2229, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2225, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2223, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2220, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2216, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2214, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2211, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2207, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2204, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2202, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2198, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2196, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2192, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2189, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2186, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2183, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2180, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2177, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2173, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2170, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2167, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2164, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2161, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2158, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2155, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2152, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2148, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2146, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2142, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2140, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2136, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2133, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2130, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2127, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2124, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2121, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2118, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2114, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2112, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2109, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2106, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2103, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2099, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2096, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2093, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2091, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2087, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2085, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2082, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2079, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2077, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2073, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2071, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2067, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2065, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2061, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2059, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2057, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2054, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2051, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2048, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2046, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2044, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2040, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2038, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2035, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2032, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2030, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2027, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2024, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2023, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2020, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2018, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2015, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2012, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2010, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2007, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2005, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2003, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2001, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1997, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1995, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1993, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1991, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1989, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1986, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1984, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1982, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1980, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1977, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1975, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1973, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1971, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1968, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1967, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1964, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1963, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1960, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1959, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1956, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1954, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1953, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1950, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1948, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1945, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1944, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1941, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1940, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1938, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1936, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1933, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1932, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1930, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1927, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1925, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1923, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1921, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1920, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1918, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1917, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1913, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1911, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1910, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1908, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1906, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1903, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1902, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1900, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1896, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1895, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1893, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1891, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1889, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1887, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1885, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1883, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1880, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1880, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1878, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1876, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1874, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1872, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1870, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1868, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1866, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1864, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1862, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1861, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1859, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1856, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1855, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1853, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1851, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1850, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1848, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1846, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1844, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1842, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1841, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1839, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1837, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1835, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1833, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1832, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1830, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1828, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1826, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1824, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1823, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1821, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1819, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1817, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1815, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1814, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1812, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1811, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1809, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1806, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1805, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1803, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1801, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1800, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1799, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1796, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1795, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1793, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1792, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1790, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1787, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1786, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1784, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1783, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1781, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1780, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1777, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1776, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1775, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1773, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1771, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1769, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1767, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1766, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1764, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1763, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1761, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1760, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1757, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1756, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1755, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1752, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1751, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1749, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1748, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1747, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1744, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1743, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1741, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1739, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1738, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1734, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1733, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1730, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1729, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1725, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1717, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1715, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1713, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1709, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1707, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1706, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1704, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1703, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1702, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1700, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1699, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1697, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1695, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1694, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1692, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1690, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1689, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1687, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1686, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1684, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1682, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1681, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1680, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1679, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1677, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1676, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1673, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1672, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1671, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1669, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1664, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1663, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1661, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1660, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1659, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1657, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1655, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1654, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1652, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1651, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1649, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1647, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1646, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1641, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1640, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1639, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1637, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1635, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1633, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1632, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1630, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1629, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1627, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1626, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1625, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1622, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1621, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1620, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1618, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1616, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1616, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1614, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1613, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1610, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1609, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1608, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1607, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1604, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1603, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1601, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1600, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1599, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1595, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1594, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1592, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1590, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1589, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1588, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1585, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1583, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1583, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1580, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1579, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1578, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1575, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1574, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1572, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1570, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1569, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1568, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1565, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1564, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1562, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1560, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1559, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1556, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1555, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1553, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1551, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1550, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1547, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1545, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1544, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1542, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1540, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1538, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1536, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1535, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1532, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1530, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1528, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1526, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1525, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1523, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1521, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1519, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1516, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1515, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1513, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1510, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1509, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1506, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1504, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1503, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1500, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1498, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1496, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1494, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1492, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1490, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1488, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1487, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1485, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1484, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1482, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1480, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1478, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1477, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1475, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1474, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1472, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1470, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1470, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1469, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1466, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1465, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1463, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1462, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1461, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1458, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1457, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1456, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1454, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1453, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1451, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1450, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1448, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1447, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1445, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1443, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1442, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1439, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1437, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1436, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1434, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1432, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1431, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1430, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1428, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1426, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1424, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1423, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1421, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1419, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1418, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1416, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1414, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1413, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1411, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1410, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1408, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1406, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1404, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1403, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1401, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1400, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1398, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1396, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1395, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1393, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1391, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1389, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1387, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1386, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1384, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1383, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1381, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1378, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1377, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1376, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1374, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1372, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1371, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1370, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1367, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1365, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1363, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1362, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1360, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1358, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1356, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1355, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1353, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1351, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1350, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1348, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1346, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1344, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1342, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1341, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1339, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1337, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1335, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1334, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1332, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1330, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1328, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1326, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1324, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1322, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1321, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1319, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1317, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1315, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1313, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1310, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1309, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1307, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1305, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1303, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1301, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1299, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1298, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1295, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1294, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1292, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1290, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1287, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1286, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1284, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1282, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1279, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1278, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1276, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1273, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1272, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1270, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1268, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1265, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1264, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1261, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1260, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1257, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1256, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1253, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1250, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1249, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1247, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1244, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1243, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1240, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1239, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1236, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1234, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1232, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1229, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1228, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1225, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1222, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1221, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1219, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1216, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1215, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1212, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1210, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1208, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1205, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1204, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1202, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1199, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1198, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1196, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1193, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1192, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1189, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1188, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1185, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1183, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1182, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1180, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1178, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1176, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1174, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1172, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1170, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1168, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1166, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1165, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1163, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1161, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1159, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1157, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1156, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1154, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1151, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1149, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1148, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1147, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1145, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1143, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1141, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1140, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1138, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1136, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1135, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1133, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1131, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1129, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1128, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1126, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1125, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1123, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1121, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1120, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1119, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1117, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1115, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1113, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1112, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1111, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1109, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1107, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1106, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1104, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1103, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1101, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1100, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1099, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1097, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1096, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1095, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1093, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1092, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1090, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1089, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1088, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1086, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1085, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1084, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1081, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1081, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1079, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1079, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1077, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1076, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1075, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1073, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1071, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1071, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1069, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1068, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1067, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1066, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1064, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1063, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1061, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1061, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1059, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1058, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1057, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1055, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1055, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1053, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1052, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1050, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1049, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1049, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1047, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1046, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1045, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1044, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1043, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1042, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1040, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1040, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1038, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1037, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1036, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1035, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1033, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1032, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1032, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1030, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1029, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1028, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1027, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1025, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1024, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1023, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1022, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1020, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1019, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1019, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1017, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1017, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1015, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1013, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1013, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1011, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1009, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1008, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1007, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1005, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1004, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1003, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1002, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1000, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0999, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0997, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0996, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0994, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0994, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0992, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0990, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0990, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0987, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0986, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0985, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0983, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0982, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0980, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0979, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0978, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0976, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0975, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0974, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0972, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0971, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0969, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0968, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0967, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0965, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0964, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0962, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0960, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0959, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0958, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0957, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0956, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0954, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0953, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0952, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0951, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0949, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0948, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0947, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0946, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0944, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0943, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0941, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0937, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0936, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0935, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0934, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0933, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0931, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0931, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0929, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0927, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0926, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0926, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0925, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0923, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0922, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0921, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0920, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0919, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0917, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0916, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0916, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0914, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0913, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0912, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0912, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0910, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0909, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0908, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0907, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0906, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0905, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0904, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0903, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0902, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0901, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0901, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0899, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0892, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0892, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0891, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0890, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0889, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0888, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0887, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0886, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0885, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0884, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0883, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0882, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0881, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0879, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0878, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0877, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0877, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0875, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0874, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0874, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0871, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0868, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0867, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0866, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0866, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0865, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0862, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0861, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0858, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0858, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0856, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0856, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0855, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0855, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0854, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0853, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0852, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0851, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0850, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0849, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0846, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0844, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0842, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0841, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0841, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0837, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0835, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0835, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0833, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0832, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0831, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0829, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0828, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0827, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0827, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0827, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0826, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0822, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0820, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0819, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0818, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0818, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0818, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0816, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0815, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0813, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0814, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0813, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0811, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0809, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0809, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0807, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0806, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0804, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0803, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0801, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0801, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0795, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0794, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0793, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0792, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0792, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0790, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0787, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0786, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0784, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0781, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0780, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0779, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0777, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0767, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0764, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0763, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0761, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0758, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0756, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0755, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0747, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0741, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0739, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0738, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0734, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0729, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0727, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0725, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0710, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0708, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0703, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0699, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0693, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0689, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0688, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0686, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0685, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0684, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0682, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0681, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0679, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0677, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0676, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0674, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0675, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0673, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0672, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0671, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0669, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0668, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0664, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0663, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0660, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0659, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0657, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0656, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0654, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0652, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0651, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0649, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0643, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0642, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0641, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0640, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0639, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0637, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0635, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0633, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0634, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0632, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0631, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0630, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0629, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0628, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0627, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0626, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0622, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0620, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0619, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0618, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0614, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0613, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0612, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0611, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0610, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0609, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0608, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0607, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0605, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0604, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0603, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0602, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0601, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0600, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0599, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0595, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0596, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0594, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0593, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0592, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0591, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0590, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0589, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0588, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0586, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0584, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0585, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0583, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0581, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0582, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0581, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 48.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengthscale: tensor([3.0741, 0.9407])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9300a065c1ca45418545c1fc7c8e785a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch = 1 -----\n",
      "Val loss = 0.4737\n",
      "\n",
      "New best epoch, loss = 0.4737\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.4453\n",
      "\n",
      "New best epoch, loss = 0.4453\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.4403\n",
      "\n",
      "New best epoch, loss = 0.4403\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.4386\n",
      "\n",
      "New best epoch, loss = 0.4386\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.4424\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.4532\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.4393\n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-04.\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.4377\n",
      "\n",
      "New best epoch, loss = 0.4377\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.4386\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.4458\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.4385\n",
      "\n",
      "Epoch 00011: reducing learning rate of group 0 to 2.5000e-04.\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.4366\n",
      "\n",
      "New best epoch, loss = 0.4366\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.4356\n",
      "\n",
      "New best epoch, loss = 0.4356\n",
      "\n",
      "----- Epoch = 14 -----\n",
      "Val loss = 0.4352\n",
      "\n",
      "New best epoch, loss = 0.4352\n",
      "\n",
      "----- Epoch = 15 -----\n",
      "Val loss = 0.4399\n",
      "\n",
      "----- Epoch = 16 -----\n",
      "Val loss = 0.4493\n",
      "\n",
      "----- Epoch = 17 -----\n",
      "Val loss = 0.4393\n",
      "\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.2500e-04.\n",
      "----- Epoch = 18 -----\n",
      "Val loss = 0.4393\n",
      "\n",
      "----- Epoch = 19 -----\n",
      "Val loss = 0.4451\n",
      "\n",
      "Stopping early\n",
      "----- Epoch = 1 -----\n",
      "Val loss = 0.253806\n",
      "\n",
      "New best epoch, loss = 0.253806\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.071291\n",
      "\n",
      "New best epoch, loss = 0.071291\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.017153\n",
      "\n",
      "New best epoch, loss = 0.017153\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.011272\n",
      "\n",
      "New best epoch, loss = 0.011272\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.009544\n",
      "\n",
      "New best epoch, loss = 0.009544\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.008768\n",
      "\n",
      "New best epoch, loss = 0.008768\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.008237\n",
      "\n",
      "New best epoch, loss = 0.008237\n",
      "\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.007854\n",
      "\n",
      "New best epoch, loss = 0.007854\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.007822\n",
      "\n",
      "New best epoch, loss = 0.007822\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.007573\n",
      "\n",
      "New best epoch, loss = 0.007573\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.007502\n",
      "\n",
      "New best epoch, loss = 0.007502\n",
      "\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.007462\n",
      "\n",
      "New best epoch, loss = 0.007462\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.007402\n",
      "\n",
      "New best epoch, loss = 0.007402\n",
      "\n",
      "----- Epoch = 14 -----\n",
      "Val loss = 0.007422\n",
      "\n",
      "----- Epoch = 15 -----\n",
      "Val loss = 0.007413\n",
      "\n",
      "----- Epoch = 16 -----\n",
      "Val loss = 0.007325\n",
      "\n",
      "New best epoch, loss = 0.007325\n",
      "\n",
      "----- Epoch = 17 -----\n",
      "Val loss = 0.007323\n",
      "\n",
      "New best epoch, loss = 0.007323\n",
      "\n",
      "----- Epoch = 18 -----\n",
      "Val loss = 0.007343\n",
      "\n",
      "----- Epoch = 19 -----\n",
      "Val loss = 0.007335\n",
      "\n",
      "----- Epoch = 20 -----\n",
      "Val loss = 0.007319\n",
      "\n",
      "New best epoch, loss = 0.007319\n",
      "\n",
      "----- Epoch = 21 -----\n",
      "Val loss = 0.007306\n",
      "\n",
      "New best epoch, loss = 0.007306\n",
      "\n",
      "----- Epoch = 22 -----\n",
      "Val loss = 0.007292\n",
      "\n",
      "New best epoch, loss = 0.007292\n",
      "\n",
      "----- Epoch = 23 -----\n",
      "Val loss = 0.007313\n",
      "\n",
      "----- Epoch = 24 -----\n",
      "Val loss = 0.007272\n",
      "\n",
      "New best epoch, loss = 0.007272\n",
      "\n",
      "----- Epoch = 25 -----\n",
      "Val loss = 0.007312\n",
      "\n",
      "----- Epoch = 26 -----\n",
      "Val loss = 0.007255\n",
      "\n",
      "New best epoch, loss = 0.007255\n",
      "\n",
      "----- Epoch = 27 -----\n",
      "Val loss = 0.007282\n",
      "\n",
      "----- Epoch = 28 -----\n",
      "Val loss = 0.007277\n",
      "\n",
      "----- Epoch = 29 -----\n",
      "Val loss = 0.007265\n",
      "\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-04.\n",
      "----- Epoch = 30 -----\n",
      "Val loss = 0.007250\n",
      "\n",
      "New best epoch, loss = 0.007250\n",
      "\n",
      "----- Epoch = 31 -----\n",
      "Val loss = 0.007242\n",
      "\n",
      "New best epoch, loss = 0.007242\n",
      "\n",
      "----- Epoch = 32 -----\n",
      "Val loss = 0.007272\n",
      "\n",
      "----- Epoch = 33 -----\n",
      "Val loss = 0.007265\n",
      "\n",
      "----- Epoch = 34 -----\n",
      "Val loss = 0.007248\n",
      "\n",
      "Epoch 00034: reducing learning rate of group 0 to 5.0000e-05.\n",
      "----- Epoch = 35 -----\n",
      "Val loss = 0.007243\n",
      "\n",
      "----- Epoch = 36 -----\n",
      "Val loss = 0.007255\n",
      "\n",
      "Stopping early at epoch = 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1749.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5278, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5276, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5275, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5274, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5273, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5272, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5271, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5269, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5269, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5267, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5266, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5265, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5264, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5262, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5260, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5259, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5259, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5258, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5256, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5254, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5254, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5250, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5250, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5248, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5248, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5246, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5245, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5243, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5241, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5240, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5239, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5237, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5236, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5234, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5233, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5231, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5229, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5228, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5226, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5225, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5223, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5222, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5220, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5218, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5217, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5215, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5213, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5212, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5210, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5208, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5206, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5205, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5203, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5201, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5199, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5198, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5196, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5194, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5192, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5191, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5188, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5187, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5185, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5184, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5182, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5180, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5178, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5176, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5174, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5172, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5171, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5168, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5167, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5165, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5163, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5160, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5159, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5158, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5155, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5154, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5151, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5150, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5147, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5145, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5144, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5142, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5138, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5137, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5135, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5134, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5131, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5129, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5127, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5126, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5123, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5122, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5119, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5117, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5114, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5113, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5111, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5108, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5106, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5104, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5102, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5100, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5097, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5095, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5092, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5090, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5087, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5085, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5082, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5080, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5077, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5074, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5072, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5069, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5066, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5062, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5060, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5057, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5053, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5051, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5047, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5044, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5041, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5037, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5034, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5030, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5027, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5023, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5020, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5016, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5012, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5010, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5006, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5003, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4999, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4996, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4992, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4988, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4986, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4982, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4979, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4975, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4972, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4969, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4966, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4963, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4959, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4956, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4953, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4950, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4947, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4944, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4941, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4937, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4935, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4931, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4928, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4925, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4922, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4919, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4916, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4912, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4909, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4906, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4903, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4899, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4893, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4890, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4887, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4884, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4880, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4877, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4874, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4871, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4867, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4863, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4860, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4858, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4854, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4851, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4847, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4843, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4840, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4837, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4833, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4830, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4827, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4822, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4819, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4815, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4812, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4810, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4806, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4798, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4800, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4793, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4795, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4789, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4780, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4780, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4777, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4772, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4767, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4765, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4760, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4758, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4756, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4749, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4744, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4743, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4736, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4738, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4727, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4717, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4713, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4708, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4702, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4698, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4695, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4691, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4687, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4683, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4680, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4676, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4672, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4669, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4666, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4662, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4658, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4654, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4651, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4648, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4640, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4636, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4633, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4629, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4626, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4623, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4618, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4615, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4612, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4608, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4606, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4601, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4598, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4595, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4591, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4588, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4584, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4581, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4577, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4574, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4570, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4567, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4564, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4559, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4556, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4554, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4550, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4547, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4544, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4541, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4537, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4534, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4530, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4527, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4524, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4520, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4517, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4514, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4511, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4507, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4504, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4501, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4497, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4494, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4491, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4487, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4484, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4481, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4477, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4474, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4471, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4468, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4464, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4461, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4458, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4454, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4451, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4448, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4444, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4441, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4437, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4435, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4431, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4428, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4426, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4421, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4418, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4391, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4411, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4408, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4405, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4401, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4397, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:13<00:00,  8.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(r'/Users/fuchuenli/Desktop/Data Science /Year 2/Trimester 2/COMP SCI 7097/GP-SHAP/Shapley Prior'))\n",
    "sys.path.append(os.path.abspath(r'/Users/fuchuenli/Desktop/Data Science /Year 2/Trimester 2/COMP SCI 7097/RKHS-SHAP'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from sklearn.datasets import load_diabetes\n",
    "import matplotlib.pylab as plt\n",
    "from gpytorch.lazy import lazify\n",
    "\n",
    "from src.gp_model.VariationalGPRegression import VariationalGPRegression\n",
    "from src.explanation_algorithms.BayesGPSHAP import BayesGPSHAP\n",
    "from src.predictive_explanation.ShapleyPrior import ShapleyPrior\n",
    "from src.utils.visualisation import summary_plot\n",
    "from src.predictive_explanation.ShapleyKernel import ShapleyKernel\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from math import comb\n",
    "\n",
    "import fastshap\n",
    "import time\n",
    "\n",
    "import os, sys, pickle, warnings, torch, shap\n",
    "\n",
    "import numpy as np\n",
    "from experiments.BananaShapley.banana_distribution import Banana2d\n",
    "from experiments.BananaShapley.gshap_banana import Observation2dBanana\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import mean_squared_error, pairwise_distances, r2_score\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap.utils import MaskLayer1d\n",
    "from fastshap import Surrogate, KLDivLoss\n",
    "from fastshap import FastSHAP\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    n_ls = [1020, 1110]\n",
    "    v = 10\n",
    "    b = 0.01\n",
    "    iterations = 10\n",
    "    results = {\"SHAP\": [], \"#Sample\": [], \"Training Time\": [], \"Implementation Time\": []}\n",
    "    for n in n_ls:\n",
    "        banana2d = Banana2d(n=n, v=v, b=b, noise=0)\n",
    "\n",
    "        # Scaled the output so that can we compare accuracy across\n",
    "        scale = 1\n",
    "        y = torch.Tensor(banana2d.y/scale)\n",
    "        X = torch.Tensor(banana2d.X)\n",
    "        d = X.shape[1]\n",
    "\n",
    "        compute_mh = lambda X: np.array([np.median(pairwise_distances(X[:, [i]])) for i in range(X.shape[1])])\n",
    "        lengthscale = torch.tensor(compute_mh(X)).float()\n",
    "        lengthscale[1] *= 1\n",
    "        print(\"Lengthscale:\", lengthscale)\n",
    "\n",
    "        # True OSVs:\n",
    "        phi1 = banana2d.phi_1/scale\n",
    "        phi2 = banana2d.phi_2/scale\n",
    "        PHI = np.array([phi1, phi2]).T\n",
    "\n",
    "        # True ISVs:\n",
    "        phi1_I = banana2d.phi_1_I\n",
    "        phi2_I = banana2d.phi_2_I\n",
    "        PHI_I = np.array([phi1_I, phi2_I]).T\n",
    "\n",
    "        cutting_points = 1000\n",
    "\n",
    "        X_train = X[:cutting_points]\n",
    "        y_train = y[:cutting_points]\n",
    "        X_test = X[cutting_points:]\n",
    "        y_test = y[cutting_points:]\n",
    "\n",
    "        PHI_train = PHI[:cutting_points]\n",
    "        PHI_test = PHI[cutting_points:]\n",
    "\n",
    "        kernel = RBFKernel\n",
    "        gp_regression = VariationalGPRegression(\n",
    "            X_train, y_train, kernel=kernel, num_inducing_points=200, batch_size=128)\n",
    "\n",
    "        gp_regression.fit(learning_rate=1e-2,\n",
    "                        training_iteration=300)\n",
    "        \n",
    "        fastshap_training_start = time.time()\n",
    "\n",
    "        surr = nn.Sequential(\n",
    "        MaskLayer1d(value=0, append=True),\n",
    "        nn.Linear(2 * d, 128),\n",
    "        nn.ELU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ELU(inplace=True),\n",
    "        nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        surrogate = Surrogate(surr, d)\n",
    "\n",
    "        def original_model(x):\n",
    "            return gp_regression.predict(x).mean.detach().reshape(-1, 1).float()\n",
    "\n",
    "        surrogate.train_original_model(\n",
    "            X_train,\n",
    "            X_test,\n",
    "            original_model,\n",
    "            batch_size=64,\n",
    "            max_epochs=100,\n",
    "            loss_fn=nn.MSELoss(),\n",
    "            validation_samples=10,\n",
    "            validation_batch_size=10000,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        explainer = nn.Sequential(\n",
    "        nn.Linear(d, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 2 * d))\n",
    "\n",
    "        # Set up FastSHAP object\n",
    "        fastshap = FastSHAP(explainer, surrogate, normalization='additive')\n",
    "\n",
    "        # Train\n",
    "        fastshap.train(\n",
    "            X_train,\n",
    "            X_test,\n",
    "            batch_size=32,\n",
    "            num_samples=32,\n",
    "            max_epochs=200,\n",
    "            validation_samples=128,\n",
    "            verbose=True)\n",
    "        \n",
    "        fastshap_training_end = time.time()\n",
    "        fastshap_training_time = fastshap_training_end - fastshap_training_start\n",
    "        fastshap_implementation_start = time.time()\n",
    "\n",
    "\n",
    "        # fastshap predictions\n",
    "        fastshap_preds = [fastshap.shap_values(X_test[i:i+1])[0].mean(axis=1) for i in range(X.shape[0] - cutting_points)]\n",
    "        fastshap_preds = torch.tensor(fastshap_preds).t()\n",
    "\n",
    "        fastshap_implementation_end = time.time()\n",
    "        fast_shap_implementation_time = fastshap_implementation_end - fastshap_implementation_start\n",
    "\n",
    "        results[\"SHAP\"].append(\"FastSHAP\")\n",
    "        results[\"#Sample\"].append(n)\n",
    "        results[\"Training Time\"].append(fastshap_training_time)\n",
    "        results[\"Implementation Time\"].append(fast_shap_implementation_time)\n",
    "\n",
    "        bayesgpshap = BayesGPSHAP(train_X=X, kernel=RBFKernel(), gp_model=gp_regression,\n",
    "                            include_likelihood_noise_for_explanation=False, scale=scale)\n",
    "        bayesgpshap.run_bayesSHAP(X=X, num_coalitions=2**d)\n",
    "        explanations = bayesgpshap.mean_shapley_values\n",
    "        shapley_prior_training_start = time.time()\n",
    "        target = explanations.t().reshape(-1, 1)\n",
    "        shapley_kernel = ShapleyKernel(\n",
    "            train_X=X, kernel=RBFKernel(), lengthscales=gp_regression.lengthscale, \n",
    "            inducing_points=gp_regression.inducing_points,\n",
    "            num_coalitions=2**d, sampling_method=\"subsampling\", verbose=False\n",
    "        )\n",
    "\n",
    "        target_train = target[:cutting_points*d]\n",
    "\n",
    "        optim = torch.optim.Adam(shapley_kernel.parameters(), lr=1e-3)\n",
    "        def loss_function(pred, true):\n",
    "            return torch.mean((true - pred) **2)\n",
    "\n",
    "        min_loss = np.inf\n",
    "        early_stopping = 0\n",
    "        while True:\n",
    "            optim.zero_grad()\n",
    "            Psi = shapley_kernel(X)\n",
    "            K = torch.einsum(\"ijk,lmn->imkn\", Psi, Psi.transpose(0, 1))\n",
    "            K = K.permute(2, 0, 3, 1).resize(len(target), len(target))\n",
    "            K_train = K[:cutting_points*d, :cutting_points*d]\n",
    "            prediction = K_train @ lazify(K_train).add_diag(shapley_kernel.krr_regularisation).inv_matmul(target_train)\n",
    "            loss = loss_function(prediction, target_train)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            if loss >= min_loss:\n",
    "                    early_stopping += 1\n",
    "            else:\n",
    "                min_loss = loss\n",
    "                early_stopping = 0\n",
    "                \n",
    "            if early_stopping >= 5:\n",
    "                break\n",
    "        \n",
    "        shapley_prior_training_end = time.time()\n",
    "\n",
    "        shapley_prior_training_time = shapley_prior_training_end - shapley_prior_training_start\n",
    "        shapley_prior_implementation_start = time.time()\n",
    "        Psi = shapley_kernel(X)\n",
    "        K = torch.einsum(\"ijk,lmn->imkn\", Psi, Psi.transpose(0, 1))\n",
    "        K = K.permute(2, 0, 3, 1).resize(len(target), len(target))\n",
    "\n",
    "        K_train = K[:cutting_points*d, :cutting_points*d]\n",
    "        K_test_train = K[cutting_points*d:, :cutting_points*d]\n",
    "\n",
    "        train_target = target[:cutting_points*d]\n",
    "        test_target = target[cutting_points*d:]\n",
    "\n",
    "        pred = K_test_train @ lazify(K_train).add_diag(shapley_kernel.krr_regularisation).inv_matmul(train_target)\n",
    "        pred = pred.reshape((-1, 2)).detach().numpy()\n",
    "        shapley_prior_implementation_end = time.time()\n",
    "        shapley_prior_implementation_time = shapley_prior_implementation_end - shapley_prior_implementation_start\n",
    "\n",
    "        results[\"SHAP\"].append(\"ShapleyPrior\")\n",
    "        results[\"#Sample\"].append(n)\n",
    "        results[\"Training Time\"].append(shapley_prior_training_time)\n",
    "        results[\"Implementation Time\"].append(shapley_prior_implementation_time)\n",
    "\n",
    "        # Assume this is your custom model class\n",
    "        class CustomModel:\n",
    "            def predict_custom(self, data):\n",
    "                # Your prediction logic here\n",
    "                pred = []\n",
    "                for i in range(data.shape[0]):\n",
    "                    pred.append(gp_regression.predict(torch.Tensor(data[i]).reshape((1,d))).loc.item())\n",
    "                return np.array(pred)\n",
    "\n",
    "        # Create an instance of your model\n",
    "        model = CustomModel()\n",
    "\n",
    "        # Define a wrapper function for the model's prediction\n",
    "        def model_predict(data):\n",
    "            return model.predict_custom(data)\n",
    "        \n",
    "        gshap_implementation_start_time = time.time()\n",
    "\n",
    "        ogshap = Observation2dBanana(model_predict, X_test.numpy())\n",
    "        ophi1, ophi2 = ogshap.fit(X_test, num_samples=X_test.shape[0])    \n",
    "        OPHI = np.array([ophi1,ophi2]).T\n",
    "\n",
    "        gshap_implementation_end_time = time.time()\n",
    "        gshap_implementation_time = gshap_implementation_end_time - gshap_implementation_start_time\n",
    "        results[\"SHAP\"].append(\"GSHAP\")\n",
    "        results[\"#Sample\"].append(n)\n",
    "        results[\"Training Time\"].append(0)\n",
    "        results[\"Implementation Time\"].append(gshap_implementation_time)\n",
    "\n",
    "    sns.barplot(data=results, x=\"#Sample\", y=\"Total Time\", hue=\"SHAP\")\n",
    "    plt.title(\"SHAP Execution Time\")\n",
    "    plt.xlabel(\"#Sample\")\n",
    "    plt.ylabel(\"Time(s)\")\n",
    "    plt.savefig(\"shap_value_execution_time.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9c82b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHAP</th>\n",
       "      <th>#Sample</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Implementation Time</th>\n",
       "      <th>Total Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FastSHAP</td>\n",
       "      <td>1020</td>\n",
       "      <td>9.874937</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>9.877464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ShapleyPrior</td>\n",
       "      <td>1020</td>\n",
       "      <td>104.335335</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>104.360276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSHAP</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411583</td>\n",
       "      <td>0.411583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FastSHAP</td>\n",
       "      <td>1110</td>\n",
       "      <td>7.920091</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>7.933252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ShapleyPrior</td>\n",
       "      <td>1110</td>\n",
       "      <td>17.251732</td>\n",
       "      <td>0.028163</td>\n",
       "      <td>17.279895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GSHAP</td>\n",
       "      <td>1110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.157036</td>\n",
       "      <td>13.157036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SHAP  #Sample  Training Time  Implementation Time  Total Time\n",
       "0      FastSHAP     1020       9.874937             0.002527    9.877464\n",
       "1  ShapleyPrior     1020     104.335335             0.024941  104.360276\n",
       "2         GSHAP     1020       0.000000             0.411583    0.411583\n",
       "3      FastSHAP     1110       7.920091             0.013161    7.933252\n",
       "4  ShapleyPrior     1110      17.251732             0.028163   17.279895\n",
       "5         GSHAP     1110       0.000000            13.157036   13.157036"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results[\"Total Time\"] = results[\"Training Time\"] + results[\"Implementation Time\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ae33f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Time(s)')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=results, x=\"#Sample\", y=\"Total Time\", hue=\"SHAP\")\n",
    "plt.title(\"SHAP Execution Time\")\n",
    "plt.xlabel(\"SHAP\")\n",
    "plt.ylabel(\"Time(s)\")\n",
    "# plt.savefig(\"shap_value_execution_time.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
